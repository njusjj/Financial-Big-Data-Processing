# 实验三 171870632 史健均

###阶段一

**使用的python写的MapReduce**：

按照省份作为key，来分类；

value按照（itemid+action）来记录；

在Reduce阶段，将按照不同省份统计，该省份的不同商品关注量和购买量，建立一个字典结果如下：

dict={}

dict[key]=[{},{}]

key的值为一个包含双字典的列表，第一个字典记录关注度，第二个字典记录购买量。

结果如图：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果1.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果2.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果3.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果4.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果5.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果6.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段1结果7.png)

### 阶段二：

配置hive；

hadoop版本：2.8.5

hive版本：2.3.6

版本匹配。

下载hive-2.3.6：

> https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-2.3.6/apache-hive-2.3.6-bin.tar.gz

解压压缩包：

> tar -xzvf apache-hive-2.3.6-bin.tar.gz /Users/shijianjun

在~/.zshrc里面加上环境变量：

> export HIVE_HOME=/Users/shijianjun/hive-2.3.6
>
> export PATH=\$HIVE_HOME/bin:$PATH

修改conf下的hive-env.sh.template中的HADOOP_HOME，并存为后缀为xml的文件：

> HADOOP_HOME=/Users/shijianjun/hadoop-2.8.5

修改hive-default.xml.template为新的hive-site.xml：

> <?xml version="1.0" encoding="UTF-8" standalone="no"?>
> <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
> <configuration>
>     <property>
> 		<name>javax.jdo.option.ConnectionURL</name>
> 		<value>jdbc:derby:;databaseName=metastore_db;create=true</value>
> 	</property>
> 	<property>
> 		<name>hive.metastore.warehouse.dir</name>
> 		<value>/hive/warehouse</value>
> 	</property>
> </configuration>

启动Hive，初始化MetaStore，进入bin：

> schematool -dbType derby -initSchema

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/初始化hive.png)

启动Hive

> hive

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/hive启动.png)

####阶段2实验开始：

创建表：

> hive> CREATE TABLE  million_user_log (user_id INT, item_id INT, cat_id INT, merchant_id INT, brand_id INT, month INT, day INT, action INT, age_range INT, gender INT, province STRING) row format delimited fields terminated by ',';

将文件插入数据表中：

> hive> LOAD DATA LOCAL INPATH '/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/双十一数据/million_user_log.csv' INTO TABLE million_user_log;

#####实验第一个问题：

取购买的数据，然后计数人数，并去重：

> hive> SELECT count(DISTINCT user_id) FROM million_user_log WHERE action=2;

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/第一个问题.png)

#####实验第二个问题：

先取购买行为数据，然后按照性别分为三组，然后对每一组进行计数，对user_id去重

> hive> SELECT gender,count(DISTINCT user_id) FROM million_user_log WHERE action=2 GROUP BY gender;

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/第二个问题.png)

#####实验第三个问题：

首先选取选取浏览的数据，然后按照品牌分组，接着对每个品牌计算人数，最后按照降序排列取前十，这里用的brand_id。

> hive> SELECT brand_id,count(brand_id) number FROM million_user_log WHERE action=0 GROUP BY brand_id ORDER BY number DESC LIMIT 10;

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/第三个问题1.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/第三个问题2.png)

这次count选用user_id可以发现尽管用不同的列名，但是计数一样，所以表的所有列都被选中了：

> hive> SELECT brand_id,count(user_id) number FROM million_user_log WHERE action=0 GROUP BY brand_id ORDER BY number DESC LIMIT 10;

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/第三个问题3.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/第三个问题4.png)阶段二到此结束。

---

### 阶段三：

**先安装spark**

> https://www.apache.org/dyn/closer.lua/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz

直接在官网下载，并解压，从原始的conf文件夹下的**spark-env.sh.template****创建一个新的**spark-env.sh**文件。没有修改其他内容，然后在命令行运行

> spark-shell

如图：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/spark-shell.png)

**由于我要使用python，还需要安装pyspark**，conda install pyspark即可

> pyspark

如图：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/pyspark.png)

前者是使用scala语言，后者是python。

---

#### 阶段三的第一个任务：

- 首先读取了数据后，进行了第一次map操作，然后将此次RDD进行保存到内存中，**执行.cache()**；
- 然后对数据集，进行过滤，选取出购买的数据条目；
- 接着改变(key, value)对的结构，将省份+商品类别作为key，进行计数求和；
- 最后再次改变(key, value)结构，将省份作为key，将value中的每一对**(商品类别id，商品购买次数)**按照购买次数排序，并选取前十，进行输出。

结果如下图所示：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段31的结果1.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段31的结果2.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段31的结果3.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段31结果4.png)

---

#### 阶段三的第二个任务：

- 与第一个任务类似，此次只需要统计商品id即可，结果如下：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段32结果1.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段32结果2.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段32结果3.png)

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段32结果4.png)



**经过对比，通过Spark统计出来的结果与通过MapReduce统计出的结果一致，证明两种方法都没有问题。**

| 简单对比     | MapReduce                                                    | Spark                                                        |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 时间         | 较慢                                                         | 较快                                                         |
| 代码复杂度   | 较复杂，但python很简洁，逻辑很清晰                           | 较简单，python更简洁，但逻辑不够清晰                         |
| 使用难度     | 较易上手，便于理清逻辑，以及map，reduce的前后关系            | 较难上手，需要自行研究接口如何使用，以及教程的示例不足，不够友好。 |
| 运行便捷程度 | 很便捷，本机运行，不需要配置环境，vscode即可，还可以在vscode内部debug，利用streaming流的特点，感觉十分巧妙。 | 较为便捷，本机运行，但运行时的命令起初难以理解，而且官方文档的运行命令貌似不正确，无法运行。最终采取参数均默认的模式，方可。在不用IDEA的情况下，debug只能在命令行。 |

---

#### 阶段三的第三个任务

- 首先，我尝试用**pyspark**编程的方式解决问题，方法同前面两问，稍作修改即可。结果如下：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段33结果1.png)

**经对比，与Hive查询的结果一致。但速度比Hive快的非常多**。

---

- 接下来，尝试用**SparkSQL**直接读取数据查询来做。

> - 创建SparkSession对象
> - 读取数据，spark.read.csv，这里手动添加了标题，不然无法找到对应字段。
> - 注册为临时表
> - 使用SQL语句查询，并展示

**代码简洁，速度较快：**结果如下：

![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/阶段33的结果2.png)



| 简单对比 | Hive          | PySpark     | SparkSQL  |
| -------- | ------------- | ----------- | --------- |
| 时间     | 34.592s，很慢 | 0.06s，很快 | 1.63s较快 |
| 使用难度 | 简单          | 复杂        | 较简单    |

还有一种方式是用HIve查询，通过spark来链接Hive数据库，但是本质仍是通过Hive，这里就不再尝试。

---

### 阶段四

**综述：**

##### Spark提供了我们两个类库，ml和mllib，目前主流使用ml类库，我在下面采用的方法中，RandomForest，DecisionTree，logistics将使用ml类库，SVM将使用mllib类库。

##### 在正常的数据竞赛，如kaggle中，提供的测试集的label是未知的，应该将训练好的模型拿来预测，并提交结果。此次实验中，测试集中的label默认为正例，有10000个正例，和train.csv的数据集大小一致。问题在于：我们的train.csv中，只有小部分为正例，数目是：568个，有9432个为负例，占比94.32%，由此训练出的模型会忽略掉正例的部分作用，极大的体现负例的预测作用，事实结果也将在下面进行证明。

##### 所以，本身我还打算将测试集和训练集合并，但是实际情况下，测试集的正例不应该被当成真实的正例，是未知的，此想法也不太可行，在后面就不再使用测试集，单纯使用训练集划分，即使如此，负例仍是起到了极大的作用，预测结果很大概率仍是tp为0，但是accuracy很可观，预测不靠谱主要是数据集所致，

---

####下面将具体展示使用的几种方法以及对应的交叉检验和方法对比：

#### 逻辑回归（logistics）

**使用原因**

本实例中采用的是一个二分类的逻辑回归分类器，其中采用了弹性正则化调参。属于Elastic Net的广义线性模型家族。logistics回归属于经典回归模型，首先尝试使用。

**elasticNetParam**对应于$\alpha$，**regParam**对应于$\lambda$。

两个参数在运行中，主要参与如下表达式：

$\lambda[\frac{1}{2}(1-\alpha)||\beta||_2^2+\alpha||\beta||_1]$

$\lambda$是共有参数，当$\alpha=0$时为Ridge回归。$\alpha=1$时为Lasso回归。

####划分训练集，第一次简单试验：

预处理阶段，对数据采取了格式转换，将**csv**格式的数据转化为了便于spark读取分析的**libsvm**格式。不然后面还需要提取label，以及压缩其他特征变量为features vector。转化成libsvm就已经是符合要求的格式了，可以直接通过对dataframe使用如下语句访问label和features列：

> df.label df.features

然后对数据集进行随机划分，比如三七分。七为训练集，三为测试集。

然后拟合模型，通过**sklearn**引入混淆矩阵，得出tp，tn，fn，fp四个值，可以计算出准确率等指标。

实验发现：由于数据集的原因，accuracy指标很高，但是本身正例过少

| tn   | fp   | fn   | tp   | accuracy  | AUC  |
| ---- | ---- | ---- | ---- | --------- | ---- |
| 2892 | 0    | 151  | 0    | 0.9503779 | 0.5  |

#### 交叉检验：

下面进行了交叉检验，以期望获得更好的效果，同时也是机器学习中鲁棒性最高的一种检验方式之一。

我们采用10-fold交叉检验：

构建评估对象：

> evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')

构建网格线：$\lambda$选取0.1和0.3，$\alpha$选取0.0和0.8，交叉产生四组参数，配合10-fold，总共40组数据进行训练。

```python
paramGrid = (ParamGridBuilder()
             .addGrid(lr.regParam, [0.1, 0.3]) # regularization parameter lambdfa
             .addGrid(lr.elasticNetParam, [0.0,0.8]) # Elastic Net Parameter (Ridge = 0) 
             .build())
```

构建交叉检验：

```python
crossval = CrossValidator(estimator=lr,
                          estimatorParamMaps=paramGrid,
                          evaluator=evaluator,
                          numFolds=10) 
```

采取同样方式得出各指标值如下：

| tn   | fp   | fn   | tp   | accuracy | AUC      |
| ---- | ---- | ---- | ---- | -------- | -------- |
| 2803 | 0    | 170  | 0    | 0.942818 | 0.499999 |

通过交叉检验，查看最优模型参数：

```python
		parameter = cvModel.getEstimatorParamMaps()
    evaluation = cvModel.avgMetrics

    param_result = []

    for params, eva in zip(parameter, evaluation):
        param_map = {}
        for key, param_val in zip(params.keys(), params.values()):
            param_map[key.name]=param_val
        param_result.append((param_map, eva))

    sorted(param_result, key=lambda x:x[1], reverse=True)
    print(param_result)
```

| $\lambda$ | $\alpha$ | AUC      |
| --------- | -------- | -------- |
| 0.1       | 0.0      | 0.499999 |
| 0.1       | 0.8      | 0.499999 |
| 0.3       | 0.0      | 0.499999 |
| 0.3       | 0.8      | 0.499999 |

我们发现，显然效果并不理想，由于数据集的原因，交叉检验也没能发挥出好的效果。

---

#### 支持向量机（SVM）

**使用原因**

SVM可以使用核函数可以向高维空间进行映射，解决非线性的分类，分类效果比较好。不需要任何领域知识和参数假设。

本实验中，SVM采用的是mllib包。

SVM的操作类似于阶段三基于RDD的系列操作，然后需要对RDD进行处理，比如map操作等

```python
def parsePoint(line):
    values = [float(x) for x in line.split(',')]
    return LabeledPoint(values[4], values[0:3])
parsedData = data.map(parsePoint)
...
model = SVMWithSGD.train(trainData, iterations=100)
labelsAndPreds = testData.map(lambda p: (p.label, model.predict(p.features)))
...
```

随机划分数据集然后实验。得出结果如下：

> **Accuracy=0.943163，Recall=0**，意味着True Positive仍为0，此为数据集所致

---

#### 决策树（DecisionTree）

**使用原因**

速度快，挖掘出来的分类规则准确性高, 便于理解, 决策树可以清晰的显示哪些字段比较重要, 即可以生成可以理解的规则。

本实验中决策树采用的ml包。

```python
dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')
evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label'
```

####交叉检验

同样进行交叉检验，采用5-fold，网格参数设定Maxdepth：3，4，获得各指标如下：

| tn   | fp   | fn   | tp   | accuracy | AUC   |
| ---- | ---- | ---- | ---- | -------- | ----- |
| 2858 | 3    | 202  | 0    | 0.933072 | 0.501 |

交叉检验参数选取结果：

| max_depth | AUC   |
| --------- | ----- |
| 3         | 0.5   |
| 4         | 0.501 |

---

#### 随机森林（RandomForest）

**使用原因**

随机森林可以视为多颗决策树的集成，鲁棒性更强，泛化能力更好，不易产生过拟合现象。随机森林相对于决策树来讲没有那么好的可解释性，但其显著优势在于不必担心超参值的选择.不需要对随机森林进行剪枝，因为相对于单棵决策树来讲，集成模型对噪声的鲁棒性更好。

**逻辑**

- 使用bootstrap抽样方法随机选择N个样本用于训练（从训练集中随机可重复地选择N个样本）。
- 使用第1步选定的样本来构造一个决策树。节点划分规则如下：
  - 不重复地随机选择d个特征
  - 根据目标函数的要求，如最大化信息增益，使用选定的特征对节点进行划分

- 重复上述过程至一定迭代次数。
- 汇总每棵树的类标进行多数投票。比如对于二分类类标，总共有15棵树，有10棵树分为1,5棵树分为0，则多数服从少数，最终结果为1。

```python
rf = RandomForestClassifier(featuresCol='features', labelCol='label')
evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')
```

####交叉检验

**在实践中，我们真正需要关心的参数是为构建随机森林所需的决策树数量，决策树的数量越多，随机森林整体的分类表现越好，但这会增加计算成本**。

```python
# Focus on the number of trees
paramGrid = ParamGridBuilder().addGrid(rf.numTrees,[10,20]).build()
# Create cross validation object
crossval = CrossValidator(estimator=rf,
		estimatorParamMaps=paramGrid,evaluator=evaluator,numFolds=5) 
# Fit the model
cvModel = crossval.fit(trainData)
prediction_lr = cvModel.transform(testData)
```

得出各指标如下：

| tn   | fp   | fn   | tp   | accuracy | AUC  |
| ---- | ---- | ---- | ---- | -------- | ---- |
| 2842 | 0    | 174  | 0    | 0.942307 | 0.5  |

| Number of trees | AUC     |
| --------------- | ------- |
| 20              | 0.5     |
| 10              | 0.49999 |

可以看出，仍然是数据集导致效果不好，但决策树数目变多，会使得效果略微提升。

----

#### 四种方法对比：

|              | **Logistics** | **SVM**  | **DecisionTree** | **RandomForest** |
| ------------ | ------------- | -------- | ---------------- | ---------------- |
| **Time**     | Slower        | Faster   | Faster           | Slower           |
| **Accuracy** | 0.942818      | 0.943163 | 0.933072         | 0.942307         |

 ![avator](/Users/shijianjun/学习资料/金融大数据处理/作业/实验3/comparison.png)

还是SVM略胜一筹。

---

#### 实验结论

- SVM的算法效果略优于其他算法。
- 随机森林的性能远高于决策树，运算代价可以的话，还是选择随机森林较好。
- logistics经典算法，二分类上的表现力也不俗，值得尝试。
- 此实验预测的准确率多来源于不回头的顾客，数据集存在问题，但模型没有明显问题。
- 交叉检验仍然是比随机划分单一训练的效果更优。
- 这个实验代码不难，但各接口怎么用需要花时间学习。
- python很简洁。

### 参考文献：

- https://spark.apache.org/docs/latest/ml-classification-regression.html

- http://spark.apache.org/docs/latest/mllib-linear-methods.html#classification

- http://spark.apache.org/docs/latest/ml-classification-regression.html

---

END                                                                                                                                                   

by 史健均 171870632